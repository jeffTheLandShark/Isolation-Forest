{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e354ea9f",
   "metadata": {},
   "source": [
    "# Term Project - Isolation Forest for Anomaly Detection\n",
    "> Leigh Goetsch </br>\n",
    "> CSC 5601 - Theory of Machine Learning </br>\n",
    "> Milwaukee School of Engineering </br>\n",
    "> Fall 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87792a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from isolation_forest import IsolationForest\n",
    "import pandas as pd\n",
    "from scipy import io as sio\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab8e1a",
   "metadata": {},
   "source": [
    "# Load and view dataset\n",
    "Each patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: Normal (NO) and Abnormal (AB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841093ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../Data/IRIS.csv\"\n",
    "data_path = \"../Data/TUANDROMD.csv\"\n",
    "df_data = pd.read_csv(data_path)\n",
    "\n",
    "# drop cols with identical values\n",
    "nunique = df_data.nunique()\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "df_data = df_data.drop(columns=cols_to_drop)\n",
    "# drop nulls\n",
    "df_data = df_data.dropna()\n",
    "df_data[\"target\"] = np.where(df_data[\"target\"] == 1, 0, 1)  # make anomalies = 1\n",
    "\n",
    "X = df_data.drop(columns=[\"target\"]).values\n",
    "y = df_data[\"target\"].values\n",
    "\n",
    "df_data[\"target\"].value_counts(), df_data[\"target\"].value_counts(normalize=True)\n",
    "\n",
    "# plot ditribution of classes vs features\n",
    "# sns.pairplot(df_data, hue='target', diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b0806",
   "metadata": {},
   "source": [
    "## Isolation Forest setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(random_state=42, contamination=0.205)\n",
    "predictions = iso_forest.fit_predict(X)\n",
    "\n",
    "print(classification_report(y, predictions, target_names=[\"Inlier\", \"Outlier\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ec749",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = iso_forest.feature_importances_()\n",
    "feature_names = df_data.columns.drop(\"target\")\n",
    "importance_lookup = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "importance_df = pd.DataFrame(\n",
    "    list(importance_lookup.items()), columns=[\"Feature\", \"Importance\"]\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for feature in feature_names:\n",
    "    # group once per feature\n",
    "    grp = df_data.groupby([feature, \"target\"]).size().unstack(\"target\", fill_value=0)\n",
    "    grp = grp.rename(columns={0: \"inliers\", 1: \"outliers\"})\n",
    "\n",
    "    # total counts for that feature\n",
    "    total = df_data[feature].value_counts().rename(\"total_count\")\n",
    "\n",
    "    # merge and tidy\n",
    "    merged = grp.merge(total, left_index=True, right_index=True)\n",
    "    merged[\"feature\"] = feature\n",
    "    merged[\"importance\"] = importance_lookup[feature]\n",
    "    merged.reset_index(inplace=True)\n",
    "    merged.rename(columns={feature: \"value\"}, inplace=True)\n",
    "\n",
    "    rows.append(merged)\n",
    "\n",
    "info_df = pd.concat(rows, ignore_index=True)\n",
    "info_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot feature importance vs outlier ratio for each feature\n",
    "info_df[\"fraction_outliers\"] = info_df[\"outliers\"] / info_df[\"total_count\"]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=info_df,\n",
    "    x=\"importance\",\n",
    "    y=\"fraction_outliers\",\n",
    "    size=\"total_count\",\n",
    "    hue=\"value\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.title(\"Feature Importance vs Outlier Ratio\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Outlier Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f64995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_value_counts = df_data.melt(\n",
    "#     id_vars=[\"target\"],\n",
    "#     value_vars=importance_df[\"Feature\"].tolist(),\n",
    "#     var_name=\"Feature\",\n",
    "#     value_name=\"value\",\n",
    "# ).groupby([\"Feature\", \"value\"]).size().reset_index(name=\"Frequency\")\n",
    "\n",
    "# merged_df = pd.merge(\n",
    "#     importance_df, feature_value_counts, on=[\"Feature\"]\n",
    "# )\n",
    "# feature_value_counts\n",
    "# # pairplot of top 3 features colored by target\n",
    "# sns.pairplot(\n",
    "#     merged_df[merged_df[\"Feature\"].isin(top_features[\"Feature\"])],\n",
    "#     hue=\"target\",\n",
    "#     diag_kind=\"kde\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f84937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap visualization of predictions vs actual\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pd.crosstab(y, predictions, rownames=['Actual'], colnames=['Predicted']), annot=True, fmt='d')\n",
    "plt.title('Heatmap of Actual vs Predicted Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../Data/vertebral.mat'\n",
    "# data_path = \"../Data/satellite.mat\"\n",
    "# data_path = \"../Data/satimage-2.mat\"\n",
    "mat = sio.loadmat(data_path)\n",
    "\n",
    "X = mat['X']\n",
    "y = mat['y'].flatten()\n",
    "feature_names = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "df_vertebral = pd.DataFrame(X, columns=feature_names)\n",
    "df_vertebral[\"target\"] = y\n",
    "\n",
    "\n",
    "iso_forest = IsolationForest(random_state=42, contamination=0.205)\n",
    "predictions = iso_forest.fit_predict(X)\n",
    "print(classification_report(y, predictions, target_names=[\"Inlier\", \"Outlier\"]))\n",
    "\n",
    "# scatter grid of all feature pairs\n",
    "pd.plotting.scatter_matrix(\n",
    "    df_vertebral[feature_names],\n",
    "    c=y,\n",
    "    figsize=(10, 10),\n",
    "    marker=\"o\",\n",
    "    hist_kwds={\"bins\": 20},\n",
    "    s=60,\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    df_vertebral[feature_names],\n",
    "    c=predictions,\n",
    "    figsize=(10, 10),\n",
    "    marker=\"o\",\n",
    "    hist_kwds={\"bins\": 20},\n",
    "    s=60,\n",
    "    alpha=0.8,\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc5601",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
